\documentclass[a4paper,11pt]{article}
\title{The application of noisy-channel coding techniques to synthetic DNA barcoding}
\author{\begin{tabular}{rl}
                Name:& Izaak van Dongen\\
           EP Mentor:& Nicolle Mcnaughton\\
               Tutor:& Paul Ingham\\
        Candidate No:&  6659\\
        \end{tabular}
        }

% so the title can be accessed by fancyhdr (and is automatically correctly
% spelled etc)
\makeatletter
\let\thetitle\@title
\makeatother

% fonts
\usepackage[p,osf]{cochineal}
\usepackage[scale=.95,type1]{cabin}
\usepackage[cochineal,bigdelims,cmintegrals,vvarbb]{newtxmath}
% fixed width font with 80 chars per listing line
\usepackage[scaled=.94]{newtxtt}
\usepackage[cal=boondoxo]{mathalfa}

% make the document take up more of the page
\usepackage[margin=1in,headheight=13.6pt]{geometry}

% no paragraph indent
\usepackage[parfill]{parskip}

% custom document header/footer
\usepackage{fancyhdr}
\usepackage{lastpage}

\pagestyle{fancy}
\fancyhf{}
\lhead{\thetitle}
\rhead{Izaak van Dongen}
\rfoot{Page \thepage\ of \pageref{LastPage}}

% pretty table rules and multirow entries. Also page-breaking tables
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{longtable}

% plotting mathematical functions (needs version request)
\usepackage{pgfplots}
\pgfplotsset{compat=1.15}

% \url function and clickable table of contents. no ugly red boxes though
\usepackage[hidelinks]{hyperref}

% maths symbols and other stuff (supersedes the ams* packages)
\usepackage{mathtools}

% For framing definitions
\usepackage[framemethod=tikz]{mdframed}
\usepackage[most]{tcolorbox}

\newtcolorbox{definition}{
freelance,
before=\par\vspace{2\bigskipamount}\noindent,
after=\par\bigskip,
frame code={
  \node[
  anchor=south west,
  inner xsep=8pt,
  xshift=8pt,
  rounded corners=5pt,
  font=\bfseries\color{white},
  fill=gray] at (frame.north west) (tit) {\strut Definition:};
  \draw[
  line width=3pt,
  rounded corners=5pt,gray
  ] (tit.west) -| (frame.south west) -- ([xshift=15pt]frame.south west);
},
interior code={},
top=2pt
}

% for better table of contents stuff, providing the \listof* commands and not
% listing the tables in the table of contents
\usepackage[nottoc,notlof,notlot]{tocbibind}

% more advanced handling of utf8 and fonts or something. apparently good to have
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

% bibliography management with square braces for citations
\usepackage[square,numbers]{natbib}

% graphics, like eps files and stuff (supersedes graphics)
\usepackage{graphicx}

% used to horizontally align floats
\usepackage{subfig}

% used for figures
\usepackage{float}

% needed for colouring and stuff (xcolor supersedes color)
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{ 0,0.6,0}

% listings of code
\usepackage{minted}
\setminted{breaklines,
           breakbytokenanywhere,
           linenos
}
\usemintedstyle{friendly}
% bigger line numbers
\renewcommand\theFancyVerbLine{\footnotesize\arabic{FancyVerbLine}}

% that can break across pages while being captioned figures
\usepackage{caption}
\newenvironment{longlisting}
{\addvspace{\baselineskip}\captionsetup{type=listing}}
{\addvspace{\baselineskip}}

% allow maths to break across pages
\allowdisplaybreaks

\begin{document}
    \maketitle\thispagestyle{empty} % no page number under title
    \tableofcontents
    \listoflistings
    \listoffigures
    \listoftables

%TODO mention versioning and git
%TODO interesting as relatively new field of biology, combined with ancient
%mathematics

%TODO add mindmap
%todo the word empirical

    \section[Definitions and conventions]{Definitions \footnote{Please note that
    these definitions have been somewhat simplified. It would be impractical and
    outside of the scope of this dissertation to deliver a full briefing of
    the field of computer science.} and conventions}

    My project will involve a lot of programming. Because of the tendency for
    programmers to use field-specific vocabulary/jargon, I have provided the
    following definitions of various words I might use when talking about
    programs I write.

    \begin{definition}
    A \textbf{program} or \textbf{script}, is a sequence of instructions that the
    computer follows in order to complete a task. They are normally created and
    shown in the form of text. Roughly speaking, each line of text corresponds
    to one instruction for the computer to follow. A program in this form is
    written in a programming language.
    \end{definition}

    \begin{definition}
    A program normally also permits \textbf{input}, \textbf{arguments} or
    \textbf{parameters}. These allow a user of the program to feed it some data
    or starting instructions. This is extremely useful as it means that the
    program doesn't just do the same thing each time, but performs its task on
    the data or information requested by the user.
    \end{definition}

    \begin{definition}
    The word \textbf{code} sits kind of annoyingly here. Code may both refer to
    programming instructions or systems of symbols representing data. When
    referring to programs, code is an uncountable noun, eg ``I wrote some
    code''. When referring to symbolic systems, it \textit{is} countable, so you
    might say ``I generated some code\textit{s}, using the code I wrote earlier.
    \end{definition}

    \begin{definition}
    The programs I produce will be CLI-based. That is, they will use a
    \textbf{Command Line Interface}. This means that the user interacts with the
    program solely through text. Most applications nowadays use a graphical
    interface, but a CLI has many benefits, including but not limited to being
    easier to develop, being faster due to less overhead, CLI programs can
    interact with each other more easily as it provides a standard interface,
    and they are more portable. The downside of course is that it required more
    expertise to use, although I have sufficient experience that this is not a
    worry. All generated data will be presented in tabular format, so there is
    not really any need for a reader to be familiar with the CLI.

    An example of how I use the CLI to interact with a program is given in
    Figure \ref{figcliusage}.
    \end{definition}

\begin{figure}[H]
\begin{center}
\includegraphics[width=0.8\textwidth]{../images/cli_usage.png}
\end{center}
\caption{Example of a CLI interface}\label{figcliusage}
\end{figure}

    \begin{definition}
    A \textbf{programming language} is a defined language that both the computer
    and the programmer understand.  The programming language I'm using for this
    dissertation is Python. To produce some of by graphics, I'm using
    Postscript. On a more meta-level this dissertation itself has been produced
    with \LaTeX, and I have worked on it on a GNU/Linux system, making use of
    the shell language Zsh, and other tools like the language `Make'. None of
    these are particularly important to understanding the outcome or goals of
    this dissertation.
    \end{definition}

    \begin{definition}
    A \textbf{comment} is a section of a program which has been specially marked
    to be ignored by the computer. These are used by humans to add documentation
    or clarification to code, and are written in natural language.  In the two
    languages I'm using, comments are marked by a preceding \% or \#.
    \end{definition}

    \begin{definition}
    A \textbf{docstring} is also text within a program. It is similar to a
    comment, but there are some technical and semantic differences. Most
    importantly, a docstring is intended to describe the function of some unit
    of the code. This might be one function, one class, or of the whole program.
    A docstring is enclosed by three consecutive double quotes:
    \mintinline{python}|"""|. By convention, docstrings are written in the
    imperative mood \cite{PEPDocstrings2014Goodger}.
    \end{definition}

    \begin{definition}
    A \textbf{function} is a part of the code that acts out one specific task.
    These are useful as they can be reused, making code more maintainable (only
    one part must be modified), shorter and easier to test. Functions in Python
    are generally preceded by \mintinline{python}|def
    function_name(parameters):|.  Here, `parameters` defines which inputs the
    function expects. This allows the function to perform the same task on
    different data. All of the code within the function will then be indented
    one level.
    \end{definition}

    \begin{definition}
    One program can reuse a function from another program. To do this, the
    requesting program must \textbf{import} the function from the defining
    program. Most language also have a standard library of useful functions, so
    some imports will be from the language itself, rather than another file
    within this project.
    \end{definition}

    \begin{definition}
    A \textbf{unit test} is a way to test that a program is functioning
    correctly. It works by running a number of tests against each \textit{unit}
    of code. These units are normally functions. By making sure that each
    function works, we can be reasonably confident in how robust our code is. A
    unit test is itself also a program.
    \end{definition}

    \begin{definition}
    A \textbf{matrix} is a rectangular array of numbers. They are denoted like:
    \begin{math}
    M =
    \begin{pmatrix}
    1 & 2 & 3 \\
    4 & 5 & 5 \\
    \end{pmatrix}
    \end{math}.
    Matrices have \textbf{rows} and \textbf{columns}, which may have certain
    properties desirable for barcodes.
    \end{definition}

    For my project I have written several programs. Almost all of these are included
    within the dissertation or some other component as code listings.. When
    appropriate, I have added comments and docstrings to these, to explain
    (commentate) their function.

    In the code listings provided, comments should be highlighted
    \mintinline{python}|#like this|, and docstrings
    \mintinline{python}|"""like this"""|. All of this is demonstrated in listing
    \ref{lstcommentexample}.

\begin{longlisting}
\begin{minted}{python}
#!/usr/bin/env python3
#^ This part is a shebang. It tells the computer what language I'm using

"""
This part is a docstring and explains what all of the code does
"""

import pprint
import json

def this_is(some: "code") -> {"th": at}:
    """
    This is another docstring, but in a function, to describe what the function
    does.
    """
    for x in y:
        pprint(json.loads('{"a": 2}'))
        # This part is a comment. It explains what the following line of code
        # does, because it is particularly interesting/complicated.
        does(stuff)

        this is {a: really(long-line(of + code, [that, goes], off(the_edge), resulting in "a little arrow"}

# <- this is a comment pointing out the line numbers
\end{minted}
\caption{Example of a code listing with comments}\label{lstcommentexample}
\end{longlisting}

    \section{Introduction}
    The premise of this project is to investigate the different types of
    error-correcting codes, and how these might be applied to DNA barcoding. DNA
    barcoding is the assignment of `barcodes' to subsequences of synthesised DNA
    for the purposes of identification. This means that in future, when you look
    at that same subsequence, that should let you `ID' the whole DNA sequence.
    However, as we all know, DNA is subject to mutation, so an ideal barcode
    should still be identifiable after some number of mutations. This is where
    error-correcting codes come in.

    The challenge in this comes from the fact that most error-correcting codes
    are designed in base-2 (binary) whereas DNA strings are fundamentally
    base-4 (quaternary). The applicability of this project is that in
    oligonucleotide synthesis, some samples may need to be identified later on
    using a subsection of the sample (a barcode). These could just be linearly
    assigned codes, but this would leave them very susceptible to mutation.

    Here is an example: say that we're given a barcode of length four, to encode
    two different samples. If we worked methodically up from the bottom (using
    the ordering \texttt{ACGT} - orderings will be discussed further later on)
    we might end up with the codes \texttt{AAAA} and \texttt{AAAC}. However,
    either string would only require a single mutation (where we say a mutation
    is the changing of a single base) to become identical to the other one.
    Therefore, in this case, it would clearly be far more optimal to make a
    choice like, for example, \texttt{AAAA} and \texttt{CCCC} (although this
    leaves you with only two different codes).

    We have kind of glossed over how we in this case formally represent DNA and
    mutations, but we will get to that.

    There are also a number of parameters to the problem, and as they change
    the problem becomes increasingly hard:

    \begin{itemize}
    \item What if the barcode size changes?
    \item What if we want more codes than two?
    \item What if we anticipate many mutations?
    \end{itemize}

    All of these will be further explored in this dissertation.

    \section[Applications]{Applications \footnote{This section gives a brief
    overview of possible applications - be aware that this is somewhat
    abbreviated as this topic is not the focus of this dissertation.}}

    You may well have heard of CRISPR/Cas9, depending on which news sources you
    follow. CRISPR stands for ``Clustered Regularly Interspaced Short
    Palindromic Repeats'', which is a family of DNA sequences in bacteria
    \cite{CRISPRDailyMail,CRISPRImmune2010Horvath,WikiCrispr}. Cas9 is a
    specific CRISPR Associated Protein \cite{WikiCas9}. Together, they provide a
    mechanism for the editing of the DNA of an organism
    \cite{CRISPER2016Finneran}, by using a specific kind of virus.  This
    mechanism is shown in figure \ref{figcrispr}.

\begin{figure}[H]
\begin{center}
\includegraphics{../images/GRNA-Cas9.png}
\end{center}
\caption{Illustration of CRISPR editing DNA}\label{figcrispr}
\end{figure}

    This mechanism requires ``guide RNA (gRNA)''. This RNA may sometimes have to
    be synthesised on a large scale, and this is where the barcodes come in. If
    a large ``batch'' of gRNA contains RNA to be used for different experiments,
    this could then be barcoded in order to identify the RNA.

    This gene-editing technique has many different applications - to name a few:

    \begin{itemize}
    \item The treatment of HIV \cite{RNAHIV2014Hu}
    \item Editing the genome of a soy bean \cite{Soybean2015Li}
    \item Editing the genome of flies (Drosophila melanogaster)
          \cite{Flies2013Ren}
    \item Multiplexed editing of plant genomes \cite{PlantToolbox2015Lowder}
    \item Mutagenesis (introduction of a mutation) in maize
          \cite{Maize2015Svitashev}
    \item Genome engineering in human stem cells \cite{StemCells2013Hou}
    \end{itemize}

    This all is just one example of what could be done - there are many other
    applications \cite{WikiBarcoding}.

    \section{The Hamming distance and others}

    The Hamming distance is a measure of ``string distance''. String
    distance is a way to define how different two strings are.
    Coding-theoretically, this can be used to quantify the amount that a
    string has been changed by transmission (or an oligonucleotide has been
    mutated).

    The Hamming distance between any two equally long strings $S$ and $R$
    is given by the number of characters at identical position that differ
    \cite{Codes1950Hamming,FuzzyDistance1977SGarro}.
    For example, if we let $d_H$ denote Hamming distance, the distances
    \begin{align*}
    d_H(S, R) &= 1\\
    d_H(S, T) &= 2\\
    \text{where}\
    S &= \texttt{abcde}\\
    R &= \texttt{abc\textcolor{blue}{f}e}\\
    T &= \texttt{a\textcolor{codegreen}{x}c\textcolor{codegreen}{z}e}
    \end{align*}
    Note that for any $S$, $d(S, S) = 0$. This means that there is no
    ``distance'' from a string to itself.

    In terms of DNA, the Hamming distance can be used to determine the
    number of bases that have mutated.

    This function is implemented in listing \ref{lsthaddecode}. Hamming
    distances come up a lot in coding theory, because they are the basic way to
    quantify the error that has occurred in a message. Furthermore, various
    properties of code words can be expressed in terms of string distance. For
    example, an encoding that can correct $n$ errors must have a minimum
    distance between all strings of at least $2n$, as the whole ``radius'' of
    code words within $n$ steps from the code word all have to deterministically
    find their way back to the code word. Such a code can be said to be optimal
    if this is also the exact minimum distance, as it is taking up as much space
    as possible.

    This idea of radii also ties in to the area of sphere packing. An
    essentially equivalent formulation of the problem
    \cite{HighDensityPackings2011OToole} of generating
    efficient codes of length $n$ actually asks ``What is the most optimal
    sphere packing in dimension $n$ \cite{PackingCurvature1978Boroczky}?''. Unfortunately, this is a
    similarly difficult problem
    \cite{SphereTheorems1947Rogers,SphereUpperBounds2014DeLaat}.

    Another example is that a code that can detect $n$ errors must have a
    minimum distance of at least $2n-1$.

    The Hamming distance is not the only type of string distance - see for
    example the Levenshtein distance
    \cite{Levenshtein2001Navarro,StringToString1974Wagner}. However, it is the
    only one that ended up being directly relevant to the outcome of my
    dissertation.

    \section{Parity codes}

    \subsection{Parity}

    The insertion of ``parity bits'' is a common practice in basic encoding.
    Parity refers to the ``oddness'' or ``evenness'' of some data
    \cite{Parity2008Knuth}.

    Commonly, this is determined by making sure that the sum of the data is $0
    \pmod{2}$. This is also known as ``even parity'', and means that the total
    number of $1$-bits in the data should be even.  This means that the data is
    known to have been corrupted if its sum is odd.

    A more formal definition might be that our parity bit $b$ when applied to
    data $D$ must be such that
    \begin{align*}
    b + \sum D_i  &\equiv 0 \pmod 2 \\
    \Rightarrow b &\equiv - \sum D_i \\
                  &\equiv \sum -D_i \pmod 2\\
    \end{align*}
    Now, after transmission, assuming that at most one error has occurred, if we
    receive transmitted data $T$ and a parity bit $b_r$, we can determine if
    that error has occurred. If we allow ourselves to assume we are in binary,
    we need only flip the erroneous bit. However, if we assume the contrary for
    a moment, we can calculate the necessary change $c$ to be such that
    \begin{align*}
    b_r + c + \sum T_i &\equiv 0 \pmod 2 \\
    \Rightarrow c &\equiv -b_r - \sum T_i \pmod 2 \\
    \end{align*}
    Note that this may be shortened even further if we consider $b_r$ to be in
    $T$. I have arranged everything in this form for ease of computation in the
    long run (see listing \ref{lsthammingencode}).

    The reason that I am using such an elaborate definition with sums and
    moduluses is that I know I want to adapt my codes to base 4, and by using
    such a general definition, this is made relatively easily.

    \subsection{Simple example}

    A simple but inefficient parity encoding scheme is a column/row wise
    encoding \cite{CodeIntro2010Guruswami}. Take the slightly contrived data
    string ``\texttt{0100000101010100}''.  This is very tangentially related to
    DNA - it's the 8-bit ASCII \cite{ASCII1963ASA} representation of the string
    ``AT'', generated by the Python:
    \mintinline{python}|"".join(bin(ord(c))[2:].rjust(8, "0") for c in "AT")|
    \footnote{Sometimes I will include some `meta-code' that was used to
    generate a table or other data. Especially the smaller samples won't be as
    extensively commented as I don't consider these core programs - they are a
    kind of shortcut from writing the table out by hand.}.

    The string is then arranged in a square like so:

    \begin{center}
    \texttt{
    \begin{tabular}{cccc}
        0 & 1 & 0 & 0 \\
        0 & 0 & 0 & 1 \\ 0 & 1 & 0 & 1 \\
        0 & 1 & 0 & 0
    \end{tabular}
    }
    \end{center}

    An extra row and column, including an extra corner piece is appended like
    so:

    \begin{center}
    \texttt{
    \begin{tabular}{c c c c | c}
        0 & 1 & 0 & 0 & 1 \\
        0 & 0 & 0 & 1 & 1 \\
        0 & 1 & 0 & 1 & 0 \\
        0 & 1 & 0 & 0 & 1 \\ \hline
        0 & 1 & 0 & 0 & 1
   \end{tabular}
   }
   \end{center}

   Each of the extra bits documents the parity of its row. Using a scheme like
   this, a single corrupted bit can be detected, and corrected. For example,
   the bit at (3, 4) may have flipped like so:

    \begin{center}
    \texttt{
    \begin{tabular}{c c c c | c}
        0 & 1 & 0 & 0 & 1 \\
        0 & 0 & 0 & 1 & 1 \\
        0 & 1 & 0 & 1 & 0 \\
        0 & 1 & \textcolor{red}{1} & 0 & 1 \\ \hline
        0 & 1 & 0 & 0 & 1
   \end{tabular}
   }
   \end{center}

    Someone wishing to correct this error can check the parity of each column,
    compared with its parity bit. They can do the same for each row. Assuming
    one error has occurred, the point where the incorrect row and column cross
    is to be flipped back. In this case, the third column doesn't add up, and
    the fourth row doesn't add up, leading to the faulty bit. It is worth
    noting that this also works to correct errors in the parity bits, due the
    the extra corner bit. If only the extra corner bit seems to be wrong, it is
    the one that has flipped.

    \subsection{Limitations}

    This particularly scheme is in a sense quite inefficient. At the
    most optimal configuration, it uses on the order of $2\sqrt{n}$ parity bits,
    where $n$ is the number of bits in the message, in order to achieve 1
    correction. This can be proven as follows:

    Assume $n$ to be highly divisible. Let $p$ denote the number of parity
    bits, and $x$ denote the length of a row. We then have,
    \begin{align*}
        p &= \frac{n}{x} + x \\
        \Rightarrow \frac{dp}{dx} &= 1 - \frac{n}{x^2}
                    = 0\ \text{(as $p$ is a minimum)}\\
        \Rightarrow 1 &= \frac{n}{x^2} \\
        \Rightarrow x^2 &= n \\
        \Rightarrow x &= \sqrt{n} \\
        \Rightarrow p &= \frac{n}{\sqrt{n}} + \sqrt{n} = \sqrt{n} + \sqrt{n} \\
                      &= 2\sqrt{n} \\
    \end{align*}
    This is quite a poor asymptotic performance - as the number of data bits
    grows larger, the number of parity bits required grows relatively fast. In
    the next section, I describe a similar code that uses only $\log_2 n$. In
    figure \ref{figlogsqrtplot} is a quick plot comparing the two functions.

\begin{figure}[H]
\begin{center}
    \begin{tikzpicture}[trim axis left]
    \begin{axis}[
      domain=1:100,
      no markers,
      samples=100,
      enlarge x limits=false,
      grid=both,
legend entries={$\log_2 n$,
                $2\sqrt{n}$},
legend pos=outer north east]
    \addplot +[thick] {ln(x)/ln(2)};
    \addplot +[thick] {2 * sqrt(x)};
    \end{axis}
    \end{tikzpicture}
\end{center}
\caption{Asymptotic performance of $\log$ and $\sqrt{}$}\label{figlogsqrtplot}
\end{figure}

    As you can see, as $n$ increases the relative performance of the row-column
    approach degrades significantly.

    \section{The Hamming code}

    \subsection{Description}

    The Hamming code is actually incredibly similar to the previously described
    row/column code. It uses the same principle of parity, but the only
    difference is in how it picks its parity bits. It does this in a much more
    efficient way, as previously mentioned and graphed.

    The Hamming code instead places a parity bit at each index that is a power
    of two, where we number indices starting from 1. Therefore, our previous
    data string gains parity bits in this configuration:
    \texttt{\textcolor{red}{10}0\textcolor{red}{1}100\textcolor{red}{0}0001010\textcolor{red}{0}10100}
    (the 1st, 2nd, 4th, 8th and 16th bits are used for parity).
\
    The way the parity ``coverage'' works is shown in table
    \ref{tabhammingindices}.  I have included indices up to 31. This is
    because that is the longest encodable string with only five parity bits
    (afterwards, we have to add a parity bit at 32). Of course, a shorter code
    word can always also be encoded by just acting as if each index that is out
    of range stores a 0.

\begin{table}[H]
\begin{center}
    \begin{tabular}{crrrrrrrrrrrrrrr}
    \toprule
    Parity index & \multicolumn{15}{c}{Covered indices} \\
    \midrule
    1 & 3 & 5 & 7 & 9 & 11 & 13 & 15 & 17 & 19 & 21 & 23 & 25 & 27 & 29 & 31 \\
    2 & 3 & 6 & 7 & 10 & 11 & 14 & 15 & 18 & 19 & 22 & 23 & 26 & 27 & 30 & 31 \\
    4 & 5 & 6 & 7 & 12 & 13 & 14 & 15 & 20 & 21 & 22 & 23 & 28 & 29 & 30 & 31 \\
    8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 24 & 25 & 26 & 27 & 28 & 29 & 30 & 31 \\
    16 & 17 & 18 & 19 & 20 & 21 & 22 & 23 & 24 & 25 & 26 & 27 & 28 & 29 & 30 & 31 \\
    \bottomrule
    \end{tabular}
    \caption{Parity coverage in a Hamming code}\label{tabhammingindices}
\end{center}
\end{table}

    These are very deliberately chosen indices. In fact, this table was
    generated by a short code snippet that can be found in listing
    \ref{lsthamtab}.

    The way that it works is by considering the value of the parity index in
    binary. For example, $4_{10}=100_{2}$. As they are powers of two, they will
    always be of the form `$10*$' (a one followed by 0 or more zeroes). Each
    other index that shares that single bit of the parity index is then also
    included in its coverage \cite{Codes1950Hamming}.

    I have also generated two visualisations, which I find helpful. The first is
    table \ref{tab:hamming-binary}, which is similar to table
    \ref{tabhammingindices}, but transposed so each column corresponds to a
    parity bit, and each index is written in binary.

\begin{table}[H]
\begin{center}
\begin{tabular}{l|rrrrr}
    \toprule
    Parity index & \texttt{0000\textcolor{blue}{1}} & \texttt{000\textcolor{blue}{1}0} & \texttt{00\textcolor{blue}{1}00} & \texttt{0\textcolor{blue}{1}000} & \texttt{\textcolor{blue}{1}0000} \\
    \midrule
    \multirow{14}{*}{Coverage}
    & \texttt{0001\textcolor{blue}{1}} & \texttt{000\textcolor{blue}{1}1} & \texttt{00\textcolor{blue}{1}01} & \texttt{0\textcolor{blue}{1}001} & \texttt{\textcolor{blue}{1}0001} \\
    & \texttt{0010\textcolor{blue}{1}} & \texttt{001\textcolor{blue}{1}0} & \texttt{00\textcolor{blue}{1}10} & \texttt{0\textcolor{blue}{1}010} & \texttt{\textcolor{blue}{1}0010} \\
    & \texttt{0011\textcolor{blue}{1}} & \texttt{001\textcolor{blue}{1}1} & \texttt{00\textcolor{blue}{1}11} & \texttt{0\textcolor{blue}{1}011} & \texttt{\textcolor{blue}{1}0011} \\
    & \texttt{0100\textcolor{blue}{1}} & \texttt{010\textcolor{blue}{1}0} & \texttt{01\textcolor{blue}{1}00} & \texttt{0\textcolor{blue}{1}100} & \texttt{\textcolor{blue}{1}0100} \\
    & \texttt{0101\textcolor{blue}{1}} & \texttt{010\textcolor{blue}{1}1} & \texttt{01\textcolor{blue}{1}01} & \texttt{0\textcolor{blue}{1}101} & \texttt{\textcolor{blue}{1}0101} \\
    & \texttt{0110\textcolor{blue}{1}} & \texttt{011\textcolor{blue}{1}0} & \texttt{01\textcolor{blue}{1}10} & \texttt{0\textcolor{blue}{1}110} & \texttt{\textcolor{blue}{1}0110} \\
    & \texttt{0111\textcolor{blue}{1}} & \texttt{011\textcolor{blue}{1}1} & \texttt{01\textcolor{blue}{1}11} & \texttt{0\textcolor{blue}{1}111} & \texttt{\textcolor{blue}{1}0111} \\
    & \texttt{1000\textcolor{blue}{1}} & \texttt{100\textcolor{blue}{1}0} & \texttt{10\textcolor{blue}{1}00} & \texttt{1\textcolor{blue}{1}000} & \texttt{\textcolor{blue}{1}1000} \\
    & \texttt{1001\textcolor{blue}{1}} & \texttt{100\textcolor{blue}{1}1} & \texttt{10\textcolor{blue}{1}01} & \texttt{1\textcolor{blue}{1}001} & \texttt{\textcolor{blue}{1}1001} \\
    & \texttt{1010\textcolor{blue}{1}} & \texttt{101\textcolor{blue}{1}0} & \texttt{10\textcolor{blue}{1}10} & \texttt{1\textcolor{blue}{1}010} & \texttt{\textcolor{blue}{1}1010} \\
    & \texttt{1011\textcolor{blue}{1}} & \texttt{101\textcolor{blue}{1}1} & \texttt{10\textcolor{blue}{1}11} & \texttt{1\textcolor{blue}{1}011} & \texttt{\textcolor{blue}{1}1011} \\
    & \texttt{1100\textcolor{blue}{1}} & \texttt{110\textcolor{blue}{1}0} & \texttt{11\textcolor{blue}{1}00} & \texttt{1\textcolor{blue}{1}100} & \texttt{\textcolor{blue}{1}1100} \\
    & \texttt{1101\textcolor{blue}{1}} & \texttt{110\textcolor{blue}{1}1} & \texttt{11\textcolor{blue}{1}01} & \texttt{1\textcolor{blue}{1}101} & \texttt{\textcolor{blue}{1}1101} \\
    & \texttt{1110\textcolor{blue}{1}} & \texttt{111\textcolor{blue}{1}0} & \texttt{11\textcolor{blue}{1}10} & \texttt{1\textcolor{blue}{1}110} & \texttt{\textcolor{blue}{1}1110} \\
    & \texttt{1111\textcolor{blue}{1}} & \texttt{111\textcolor{blue}{1}1} & \texttt{11\textcolor{blue}{1}11} & \texttt{1\textcolor{blue}{1}111} & \texttt{\textcolor{blue}{1}1111} \\
    \bottomrule
\end{tabular}
\caption{Indices covered by each parity bit shown in binary - generated by
         \ref{lsthamcol}}
\label{tab:hamming-binary}
\end{center}
\end{table}

    The second is shown in figure \ref{fighamming}. It represents each covered
    bit as a filled in square, and each non-covered bit as an empty square, so
    the whole codeword is shown in every row.

\begin{figure}[H]
\begin{center}
\includegraphics{../psfiles/hamming_visualisation.eps}
\end{center}
\caption{Index coverage of Hamming parity bits - generated by \ref{lsthamps}}
\label{fighamming}
\end{figure}

    Now, when decoding a Hamming-encoded message, you check each parity bit for
    errors, as normal. You then add the index of each parity bit that shows an
    error to find the index of the corrupted bit. This bit can then be flipped.
    This can only correct one error, but it is a very effective way to do so -
    in fact, if you only want to correct one error, the Hamming code is optimal
    \cite{Codes1950Hamming,HammingCodes1997Battacharryya}.

    Of course, the Hamming code is not explicitly a way to generate barcodes -
    it is rather an encoding. However, error-correcting encodings can simply be
    applied to all possible strings to generate a set of barcodes. As we are
    using binary for now, you could generate the code corresponding to each of
    the 16 binary strings from \texttt{0000} to \texttt{1111}. This gives you 16
    barcodes of length 7 each, which can be decoded to retrieve the unique
    identifier from 0 to 15 that was associated with the DNA.

    Listing \ref{lsthammingencode} shows the program that implements a binary
    Hamming encoding.

    \subsection{Implementation}

\begin{longlisting}
\inputminted{python}{../src/encode_hamming.py}
\caption{Hamming-encoder in Python - tested by \ref{lsttesthammingencode}}
\label{lsthammingencode}
\end{longlisting}

\begin{longlisting}
\inputminted{python}{../src/decode_hamming.py}
\caption{Hamming-decoder in Python - tested by \ref{lsttesthammingdecode}}
\label{lsthammingdecode}
\end{longlisting}

    \subsection{Adaption}

    Unfortunately, this all produces binary codes, as this is more of a
    `fundamental' base in the world of computers.. As is, this is of no use
    because DNA strings are fundamentally base-4.

    \subsubsection{Na\"ive approach}

    We are quite fortunate in that 4 is a power of 2. This means that
    we can directly translate a base-4 string to binary, in the case of DNA
    perhaps by mapping the ``characters'' \texttt{ACGT} to \texttt{00 01 10 11}.

    This specific ordering is quite useful as each base pair A-T and C-G is a
    set of additive inverses mod 4, or ``number bonds to 4''. They also have the
    even stronger property that each base pair has exactly one $0$ and one $1$
    in each index. This means that for any pair $a, b \in \{0,1\}^2$, we have
    $a \oplus b = 11 \Rightarrow b = 11 \oplus a$. Effectively, this means that
    we can efficiently generate the complement of a base.

    In any case, it is absolutely trivial to write a program to excecute this
    mapping either way. Listings \ref{lsttoquat} implements conversion from
    binary to quaternary and vice versa.

\begin{longlisting}
\inputminted{python}{../src/to_quat.py}
\caption{Converting binary data to quaternary data and vice verse}
\label{lsttoquat}
\end{longlisting}

    \subsubsection{Advanced approach}

    It is also possible to directly apply some of the principles of Hamming
    encoding to base-4, with some slight modifications. The index coverage
    remains the same. In fact, the only thing that needs to be ``changed'' is
    what we do with parity. The easiest approach is to leave it almost the same
    as the previous definition (which was made somewhat cumbersome on purpose).
    We now just need to pick a parity bit so that the data sums to a multiple of
    4, rather than an even number. This means that our parity bit must now be
    generated by $b = \sum -D_i \pmod 4$. This is a suprisingly simple
    alteration, and in fact all we really need to do is parametrise the program
    by the base, as opposed to hardcoding the value $2$. I perhaps somewhat
    cheekily already taken the liberty to do this in listing
    \ref{lsthammingencode}, so all we need to do to utilise the approach is call
    that program with the right parameters.

    \subsection{Usage}

    We can now use the script to generate some data. The first set of data
    produced is shown in table \ref{tabhamdata}, and is the somewhat well-known
    Hamming-$(7,4)$ code \cite{WikiHamming74} (this also means that I can be
    sure it's correct).

    The ``usage'' of these scripts also involved testing how well they respond
    to mutations. Mutations are introduced by the code in listing
    \ref{lstmutation}. Both of these outputs are sufficiently small that they
    can be checked by eye, but for the command-line user who wishes to check
    that a larger dataset is still ordered, I have also written the script
    \ref{lstverify}.

\begin{table}[H]
\begin{center}
\begin{tabular}{rcccccc} \toprule
ID & Unencoded ID & Code & Mutated code & Recovered ID & Quaternary translation & As DNA \\ \midrule
\texttt{0} & \texttt{0000} & \texttt{0000000} & \texttt{0001000} & \texttt{0000} & \texttt{000} & \texttt{AAA} \\
\texttt{1} & \texttt{0001} & \texttt{1101001} & \texttt{1101011} & \texttt{0001} & \texttt{310} & \texttt{GCA} \\
\texttt{2} & \texttt{0010} & \texttt{0101010} & \texttt{0001010} & \texttt{0010} & \texttt{111} & \texttt{CCC} \\
\texttt{3} & \texttt{0011} & \texttt{1000011} & \texttt{1000011} & \texttt{0011} & \texttt{201} & \texttt{TAC} \\
\texttt{4} & \texttt{0100} & \texttt{1001100} & \texttt{1001110} & \texttt{0100} & \texttt{212} & \texttt{TCT} \\
\texttt{5} & \texttt{0101} & \texttt{0100101} & \texttt{0100101} & \texttt{0101} & \texttt{102} & \texttt{CAT} \\
\texttt{6} & \texttt{0110} & \texttt{1100110} & \texttt{1000110} & \texttt{0110} & \texttt{303} & \texttt{GAG} \\
\texttt{7} & \texttt{0111} & \texttt{0001111} & \texttt{0011111} & \texttt{0111} & \texttt{013} & \texttt{ACG} \\
\texttt{8} & \texttt{1000} & \texttt{1110000} & \texttt{1110000} & \texttt{1000} & \texttt{320} & \texttt{GTA} \\
\texttt{9} & \texttt{1001} & \texttt{0011001} & \texttt{0010001} & \texttt{1001} & \texttt{030} & \texttt{AGA} \\
\texttt{10} & \texttt{1010} & \texttt{1011010} & \texttt{1011010} & \texttt{1010} & \texttt{231} & \texttt{TGC} \\
\texttt{11} & \texttt{1011} & \texttt{0110011} & \texttt{0111011} & \texttt{1011} & \texttt{121} & \texttt{CTC} \\
\texttt{12} & \texttt{1100} & \texttt{0111100} & \texttt{0111100} & \texttt{1100} & \texttt{132} & \texttt{CGT} \\
\texttt{13} & \texttt{1101} & \texttt{1010101} & \texttt{1011101} & \texttt{1101} & \texttt{222} & \texttt{TTT} \\
\texttt{14} & \texttt{1110} & \texttt{0010110} & \texttt{0010110} & \texttt{1110} & \texttt{023} & \texttt{ATG} \\
\texttt{15} & \texttt{1111} & \texttt{1111111} & \texttt{1111111} & \texttt{1111} & \texttt{333} & \texttt{GGG} \\
\bottomrule
\end{tabular}
\end{center}
\caption{Data generated by \ref{lsthammingencode} and \ref{lsthammingdecode} (with formatting by
         \ref{lsthamdatatab})}
 \label{tabhamdata}
\end{table}

    Table \ref{tabhamqdata} then contains some data generated directly in base
    4, receiving a similar treatment. This is a length-3 ID encoding, so there
    were originally 64 lines, but these have been truncated after 40.

    You may notice that this data is considerably nicer than the first,
    which was first generated in binary and then translated to quaternary as a
    kind of intermediate stage. This needs fewer steps and can resist any kind
    of single mutation, so, overall, seems like a good pick.

\begin{table}[H]
\begin{center}
\begin{tabular}{rcccc} \toprule
ID & Code & Mutated code & Recovered ID & As DNA \\ \midrule
\texttt{0} & \texttt{000000} & \texttt{000000} & \texttt{000} & \texttt{AAAAAA} \\
\texttt{1} & \texttt{030301} & \texttt{130301} & \texttt{001} & \texttt{AGAGAC} \\
\texttt{2} & \texttt{020202} & \texttt{020202} & \texttt{002} & \texttt{ATATAT} \\
\texttt{3} & \texttt{010103} & \texttt{210103} & \texttt{003} & \texttt{ACACAG} \\
\texttt{4} & \texttt{300310} & \texttt{300310} & \texttt{010} & \texttt{GAAGCA} \\
\texttt{5} & \texttt{330211} & \texttt{330211} & \texttt{011} & \texttt{GGATCC} \\
\texttt{6} & \texttt{320112} & \texttt{320112} & \texttt{012} & \texttt{GTACCT} \\
\texttt{7} & \texttt{310013} & \texttt{310013} & \texttt{013} & \texttt{GCAACG} \\
\texttt{8} & \texttt{200220} & \texttt{200220} & \texttt{020} & \texttt{TAATTA} \\
\texttt{9} & \texttt{230121} & \texttt{220121} & \texttt{021} & \texttt{TGACTC} \\
\texttt{10} & \texttt{220022} & \texttt{220023} & \texttt{022} & \texttt{TTAATT} \\
\texttt{11} & \texttt{210323} & \texttt{210323} & \texttt{023} & \texttt{TCAGTG} \\
\texttt{12} & \texttt{100130} & \texttt{103130} & \texttt{030} & \texttt{CAACGA} \\
\texttt{13} & \texttt{130031} & \texttt{130031} & \texttt{031} & \texttt{CGAAGC} \\
\texttt{14} & \texttt{120332} & \texttt{120332} & \texttt{032} & \texttt{CTAGGT} \\
\texttt{15} & \texttt{110233} & \texttt{112233} & \texttt{033} & \texttt{CCATGG} \\
\texttt{16} & \texttt{331000} & \texttt{321000} & \texttt{100} & \texttt{GGCAAA} \\
\texttt{17} & \texttt{321301} & \texttt{321301} & \texttt{101} & \texttt{GTCGAC} \\
\texttt{18} & \texttt{311202} & \texttt{211202} & \texttt{102} & \texttt{GCCTAT} \\
\texttt{19} & \texttt{301103} & \texttt{301100} & \texttt{103} & \texttt{GACCAG} \\
\texttt{20} & \texttt{231310} & \texttt{211310} & \texttt{110} & \texttt{TGCGCA} \\
\texttt{21} & \texttt{221211} & \texttt{021211} & \texttt{111} & \texttt{TTCTCC} \\
\texttt{22} & \texttt{211112} & \texttt{213112} & \texttt{112} & \texttt{TCCCCT} \\
\texttt{23} & \texttt{201013} & \texttt{203013} & \texttt{113} & \texttt{TACACG} \\
\texttt{24} & \texttt{131220} & \texttt{131220} & \texttt{120} & \texttt{CGCTTA} \\
\texttt{25} & \texttt{121121} & \texttt{121122} & \texttt{121} & \texttt{CTCCTC} \\
\texttt{26} & \texttt{111022} & \texttt{111022} & \texttt{122} & \texttt{CCCATT} \\
\texttt{27} & \texttt{101323} & \texttt{101322} & \texttt{123} & \texttt{CACGTG} \\
\texttt{28} & \texttt{031130} & \texttt{331130} & \texttt{130} & \texttt{AGCCGA} \\
\texttt{29} & \texttt{021031} & \texttt{121031} & \texttt{131} & \texttt{ATCAGC} \\
\texttt{30} & \texttt{011332} & \texttt{010332} & \texttt{132} & \texttt{ACCGGT} \\
\texttt{31} & \texttt{001233} & \texttt{001213} & \texttt{133} & \texttt{AACTGG} \\
\texttt{32} & \texttt{222000} & \texttt{222300} & \texttt{200} & \texttt{TTTAAA} \\
\texttt{33} & \texttt{212301} & \texttt{232301} & \texttt{201} & \texttt{TCTGAC} \\
\texttt{34} & \texttt{202202} & \texttt{202202} & \texttt{202} & \texttt{TATTAT} \\
\texttt{35} & \texttt{232103} & \texttt{332103} & \texttt{203} & \texttt{TGTCAG} \\
\texttt{36} & \texttt{122310} & \texttt{122310} & \texttt{210} & \texttt{CTTGCA} \\
\texttt{37} & \texttt{112211} & \texttt{112211} & \texttt{211} & \texttt{CCTTCC} \\
\texttt{38} & \texttt{102112} & \texttt{132112} & \texttt{212} & \texttt{CATCCT} \\
\texttt{39} & \texttt{132013} & \texttt{132013} & \texttt{213} & \texttt{CGTACG} \\
\ldots \\
\bottomrule
\end{tabular}
\end{center}
\caption{Data generated by \ref{lsthammingencode} and \ref{lsthammingdecode} (with formatting by
         \ref{lsthamqdatatab})}
\label{tabhamqdata}
\end{table}

\begin{longlisting}
\inputminted{python}{../src/mutate.py}
\caption{Mutation-inducing code}\label{lstmutation}
\end{longlisting}

\begin{longlisting}
\inputminted{python}{../src/verify.py}
\caption{Verification script, to check validity of output}\label{lstverify}
\end{longlisting}

    \section{The Hadamard code}

    \subsection{Description}

    The Hadamard code is based on Hadamard matrices. A Hadamard matrix is a
    matrix such that each pair of rows represent a pair of orthogonal
    \cite{Orthogonal1981Burley} vectors
    \cite{HadamardMatrices1978HedayatWallis}.
    Practically, this means that each row has a Hamming distance of at least
    half of its length from each other row. This is a much stronger encoding
    than the Hamming code, so may be much more resistant to mutations. However,
    as a natural side effect of this, Hadamard codes are longer and more sparse.

    A basic generation scheme for a sequence of Hadamard matrices $H_{2^n}$ is
    given by Sylvester's construction \cite{OrthogonalMatrix1867Sylvester}:
    \begin{align*}
    H_1 &=
    \begin{pmatrix*}[r]
    1\\
    \end{pmatrix*} \\
    H_2 &=
    \begin{pmatrix*}[r]
    1 &  1 \\
    1 & -1 \\
    \end{pmatrix*} \\
    H_{2^{n + 1}} &=
    \begin{pmatrix*}[r]
    H_{2^n} &  H_{2^n} \\
    H_{2^n} & -H_{2^n} \\
    \end{pmatrix*} =
    H_2 \otimes H_{2^n},\ \text{where $\otimes$ is the Kr\"onecker product
    \cite{KroneckerProduct1955Vartak}}
    \end{align*}
    ie the next matrix is
    \begin{math}
    H_4 =
    \begin{pmatrix*}[r]
    \begin{pmatrix*}[r]
    1 &  1 \\
    1 & -1 \\
    \end{pmatrix*} &
    \begin{pmatrix*}[r]
    1 &  1 \\
    1 & -1 \\
    \end{pmatrix*} \\
    \begin{pmatrix*}[r]
    1 &  1 \\
    1 & -1 \\
    \end{pmatrix*} &
    -\begin{pmatrix*}[r]
    1 &  1 \\
    1 & -1 \\
    \end{pmatrix*} \\
    \end{pmatrix*} =
    \begin{pmatrix*}[r]
    1 &  1 &  1 &  1 \\
    1 & - 1 &  1 & - 1 \\
    1 &  1 & - 1 & - 1 \\
    1 & - 1 & - 1 &  1 \\
    \end{pmatrix*}
    \end{math}

    Note that for any such $H_{2^n}$,
    $\begin{pmatrix*}[r] H_{2^n} \\ -H_{2^n} \\ \end{pmatrix*}$
    is also a Hadamard matrix. This final version is what I will implement.

    This construction's uses the ($-$) operator, together with the set
    $\{1,-1\}$ as it's ``alphabet''. This is necessary for the satisfication of
    the ``orthogonality'' definition of Hadamard matrices, but, in fact, we need
    only a slightly weaker property, which is half of the items being different.
    I have therefore slightly modified this construction to use the Boolean
    alphabet $\{0,1\}$, and use the Boolean logical not ($\lnot$)
    \cite{BooleRecords1956Kneale}. This is more suited to this application of
    these codes, as $0$ and $1$ are the fundamental numbers that computers work
    with (known as ``bits''), so this makes the implementation more natural and
    elegant, as most programming languages have built in support for Boolean
    logic.

    The code implementing Sylvester's construction can be found in listing
    \ref{lsthadgen}.

    A visualistion of the Hadamard matrix is provided in
    figure \ref{fighadvis}. It displays the matrix as a grid, where each `1' is
    filled in.

\begin{figure}[H]
\begin{center}
\includegraphics[height=0.3\textheight]{../psfiles/hadamard_2.eps}
\includegraphics[height=0.3\textheight]{../psfiles/hadamard_3.eps}
\includegraphics[height=0.3\textheight]{../psfiles/hadamard_4.eps}
\includegraphics[height=0.3\textheight]{../psfiles/hadamard_5.eps}
\end{center}
\caption{Visualisations of ``$2^n$'' Hadamard matrices - generated by
         \ref{lsthadpy}}
\label{fighadvis}
\end{figure}

    \subsection{Implementation}

\begin{longlisting}
\inputminted{python}{../src/hadamard_matrix.py}
\caption{Hadamard matrix generation - tested by \ref{lsttesthadamardmat}}
\label{lsthadgen}
\end{longlisting}

\begin{longlisting}
\inputminted{python}{../src/hadamard_decode.py}
\caption{Hadamard matrix generation - tested by \ref{lsttesthadamarddecode}}
\label{lsthaddecode}
\end{longlisting}

    \subsection{Usage}

    Now, having written these, we can execute some tests using the same programs
    we had previously. Table \ref{tabhaddata} goes through a similar process as
    \ref{tabhamdata} and \ref{tabhamqdata}, but omits some of the stages in the
    interest of space.

    This table shows an introduction of no less than 7 mutations to each code,
    which is 32 bits long (the trade-off). This is the maximum recoverable
    error in a Sylvester Hadamard code, due to the reasons discussed in terms of
    Hamming distance earlier (Hamming distance between each code is $16$).
    However, this is a non-trivial number of bits, and is a major strength of
    the Hadamard code - it is able to recover from significant data loss. This
    means it is used in particularly noise real-world communications
    \cite{OrthogonalCodes2002Amadei}.

\begin{table}[H]
\begin{center}
\small{
\begin{tabular}{ccrc} \toprule
Code & Mutation & ID & DNA \\ \midrule
\texttt{10010110011010010110100110010110} & \texttt{10010010011010010110000110010111} & \texttt{0} & \texttt{TCCTCTTCCTTCTCCT} \\
\texttt{11000011001111000011110011000011} & \texttt{11010001001111001011111001000001} & \texttt{1} & \texttt{GAAGAGGAAGGAGAAG} \\
\texttt{10100101010110100101101010100101} & \texttt{10100101010110100100111110000101} & \texttt{2} & \texttt{TTCCCCTTCCTTTTCC} \\
\texttt{11110000000011110000111111110000} & \texttt{11110000000011010100101111110000} & \texttt{3} & \texttt{GGAAAAGGAAGGGGAA} \\
\texttt{10011001011001100110011010011001} & \texttt{10110001001000100110011010011001} & \texttt{4} & \texttt{TCTCCTCTCTCTTCTC} \\
\texttt{11001100001100110011001111001100} & \texttt{11001100001101110011001111001100} & \texttt{5} & \texttt{GAGAAGAGAGAGGAGA} \\
\texttt{10101010010101010101010110101010} & \texttt{11111010011101010101010110101010} & \texttt{6} & \texttt{TTTTCCCCCCCCTTTT} \\
\texttt{11111111000000000000000011111111} & \texttt{11111101000010000001000010110111} & \texttt{7} & \texttt{GGGGAAAAAAAAGGGG} \\
\texttt{10010110100101100110100101101001} & \texttt{10010110100001000110100101111001} & \texttt{8} & \texttt{TCCTTCCTCTTCCTTC} \\
\texttt{11000011110000110011110000111100} & \texttt{11000101110000010011110000111000} & \texttt{9} & \texttt{GAAGGAAGAGGAAGGA} \\
\texttt{10100101101001010101101001011010} & \texttt{10100111101001010100111000011010} & \texttt{10} & \texttt{TTCCTTCCCCTTCCTT} \\
\texttt{11110000111100000000111100001111} & \texttt{11110001111100000100111100001111} & \texttt{11} & \texttt{GGAAGGAAAAGGAAGG} \\
\texttt{10011001100110010110011001100110} & \texttt{10111001100110010110011001100110} & \texttt{12} & \texttt{TCTCTCTCCTCTCTCT} \\
\texttt{11001100110011000011001100110011} & \texttt{11001100000011000001000100110011} & \texttt{13} & \texttt{GAGAGAGAAGAGAGAG} \\
\texttt{10101010101010100101010101010101} & \texttt{10111010101010100001010101010001} & \texttt{14} & \texttt{TTTTTTTTCCCCCCCC} \\
\texttt{11111111111111110000000000000000} & \texttt{11101111101111110000000010000010} & \texttt{15} & \texttt{GGGGGGGGAAAAAAAA} \\
\texttt{10010110011010011001011001101001} & \texttt{10010111101010011011010001101101} & \texttt{16} & \texttt{TCCTCTTCTCCTCTTC} \\
\texttt{11000011001111001100001100111100} & \texttt{11000011001111000100001010111100} & \texttt{17} & \texttt{GAAGAGGAGAAGAGGA} \\
\texttt{10100101010110101010010101011010} & \texttt{00100101010010001010010101111010} & \texttt{18} & \texttt{TTCCCCTTTTCCCCTT} \\
\texttt{11110000000011111111000000001111} & \texttt{01010000000011111111000000001111} & \texttt{19} & \texttt{GGAAAAGGGGAAAAGG} \\
\texttt{10011001011001101001100101100110} & \texttt{10011111011001101001100101100111} & \texttt{20} & \texttt{TCTCCTCTTCTCCTCT} \\
\texttt{11001100001100111100110000110011} & \texttt{11001100101010111100110000111001} & \texttt{21} & \texttt{GAGAAGAGGAGAAGAG} \\
\texttt{10101010010101011010101001010101} & \texttt{10101010010001101010101001010100} & \texttt{22} & \texttt{TTTTCCCCTTTTCCCC} \\
\texttt{11111111000000001111111100000000} & \texttt{11011111000000001111111100001000} & \texttt{23} & \texttt{GGGGAAAAGGGGAAAA} \\
\texttt{10010110100101101001011010010110} & \texttt{11010100100001101001011000010110} & \texttt{24} & \texttt{TCCTTCCTTCCTTCCT} \\
\texttt{11000011110000111100001111000011} & \texttt{11010011100000011100001111100011} & \texttt{25} & \texttt{GAAGGAAGGAAGGAAG} \\
\texttt{10100101101001011010010110100101} & \texttt{10000101101001011000010110100101} & \texttt{26} & \texttt{TTCCTTCCTTCCTTCC} \\
\texttt{11110000111100001111000011110000} & \texttt{11100001110000001111000011110000} & \texttt{27} & \texttt{GGAAGGAAGGAAGGAA} \\
\texttt{10011001100110011001100110011001} & \texttt{10001101100110011001100110111101} & \texttt{28} & \texttt{TCTCTCTCTCTCTCTC} \\
\texttt{11001100110011001100110011001100} & \texttt{11001100110001001000110001011101} & \texttt{29} & \texttt{GAGAGAGAGAGAGAGA} \\
\texttt{10101010101010101010101010101010} & \texttt{10101010101010111010101011101010} & \texttt{30} & \texttt{TTTTTTTTTTTTTTTT} \\
\texttt{11111111111111111111111111111111} & \texttt{10101110101111111111100111111111} & \texttt{31} & \texttt{GGGGGGGGGGGGGGGG} \\
\texttt{01101001100101101001011001101001} & \texttt{01101011100101001001011011100001} & \texttt{32} & \texttt{CTTCTCCTTCCTCTTC} \\
\texttt{00111100110000111100001100111100} & \texttt{00111000111000111100100100111000} & \texttt{33} & \texttt{AGGAGAAGGAAGAGGA} \\
\texttt{01011010101001011010010101011010} & \texttt{01011010101000011010010101010111} & \texttt{34} & \texttt{CCTTTTCCTTCCCCTT} \\
\texttt{00001111111100001111000000001111} & \texttt{00001111111100001101110010001111} & \texttt{35} & \texttt{AAGGGGAAGGAAAAGG} \\
\texttt{01100110100110011001100101100110} & \texttt{01101110100110111001000101100010} & \texttt{36} & \texttt{CTCTTCTCTCTCCTCT} \\
\texttt{00110011110011001100110000110011} & \texttt{10110011110011001001110100100001} & \texttt{37} & \texttt{AGAGGAGAGAGAAGAG} \\
\texttt{01010101101010101010101001010101} & \texttt{01010101101010011010111001010101} & \texttt{38} & \texttt{CCCCTTTTTTTTCCCC} \\
\texttt{00000000111111111111111100000000} & \texttt{00000000101111111111001000100000} & \texttt{39} & \texttt{AAAAGGGGGGGGAAAA} \\
\ldots \\
\bottomrule
\end{tabular}
}
\end{center}
\caption{Testing Hadamard code programs \ref{lsthadgen} and \ref{lsthaddecode}
         (with formatting by \ref{lsthaddatatab})}
\label{tabhaddata}
\end{table}

    \section{Unit tests}

    For all the core programs, I have also written unit tests. These aim to
    verify that the program works by presenting a number of test cases, and
    seeing if the program produces the correct output. These both help to ensure
    correct behaviour, and can serve as a more practical reference of how I
    expect functions to behave.

\begin{longlisting}
\inputminted{python}{../src/test_encode_hamming.py}
\caption{Unit tests for encode\_hamming - listing \ref{lsthammingencode}}
\label{lsttesthammingencode}
\end{longlisting}

\begin{longlisting}
\inputminted{python}{../src/test_decode_hamming.py}
\caption{Unit tests for decode\_hamming - listing \ref{lsthammingdecode}}
\label{lsttesthammingdecode}
\end{longlisting}

\begin{longlisting}
\inputminted{python}{../src/test_hadamard_matrix.py}
\caption{Unit tests for hadamard\_matrix - listing \ref{lsthadgen}}
\label{lsttesthadamardmat}
\end{longlisting}

\begin{longlisting}
\inputminted{python}{../src/test_hadamard_decode.py}
\caption{Unit tests for hadamard\_decode - listing \ref{lsthaddecode}}
\label{lsttesthadamarddecode}
\end{longlisting}

    \section{Miscellaneous listings}

    Below are all the listings that I don't consider to be important to the DNA
    barcoding part of my dissertation, but have still included as it is material
    that I have produced for my project, and illustrate some of the work that
    has gone into the production of the actual dissertation.

\begin{longlisting}
\begin{minted}{python}
for p_ind in (1 << pwr for pwr in range(5)):
    print(r"    {} \\".format(" & ".join(str(i) for i in range(1, 33) if i & p_ind)))
\end{minted}
\caption{Generating Hamming coverage indices}\label{lsthamtab}
\end{longlisting}

\begin{longlisting}
\begin{minted}{python}
def add_color(s, ind):
    return r"{}\textcolor{{blue}}{{{}}}{}".format(s[:ind], s[ind], s[ind+1:])

table = zip(*[[i for i in range(1, 33) if i & p_ind] for p_ind in (1 << pwr for pwr in range(5))])
print("\n".join(r"    {} \\".format(" & ".join(r"\texttt{{{}}}".format(add_color(bin(i)[2:].rjust(5, "0"), 4 -sig_ind))
            for sig_ind, i in enumerate(row)))
            for row in table))
\end{minted}
\caption{Generating binary table}\label{lsthamcol}
\end{longlisting}

\begin{longlisting}
\begin{minted}{python}
from encode_hamming import generate_codes
from decode_hamming import hamming_decode
from mutate import mutate
from to_quat import to_quat
from as_dna import to_dna
print(r"\begin{tabular}{rcccccc} \toprule")
print(r"ID & Unencoded ID & Code & Mutated code & Recovered ID & Quaternary translation & As DNA \\ \midrule")
for ind, code in enumerate(generate_codes(2, 4)):
    scode = "".join(map(str, code))
    mut = mutate(scode, 2, 1, "01")
    recov = "".join(map(str, hamming_decode([int(c) for c in mut], 2)))
    print((" & ".join([r"\texttt{{{}}}"] * 7) + r" \\").format(ind, f"{ind:04b}", scode, mut, recov, to_quat(scode), to_dna(to_quat(scode))))
print(r"\bottomrule")
print(r"\end{tabular}")
\end{minted}
\caption{Formatting table of data \ref{tabhamdata}}\label{lsthamdatatab}
\end{longlisting}

\begin{longlisting}
\begin{minted}{python}
from encode_hamming import generate_codes
from decode_hamming import hamming_decode
from mutate import mutate
from as_dna import to_dna
print(r"\begin{tabular}{rcccc} \toprule")
print(r"ID & Code & Mutated code & Recovered ID & As DNA \\ \midrule")
for ind, code in takewhile(lambda ic: ic[0] < 40, enumerate(generate_codes(4, 3))):
    scode = "".join(map(str, code))
    mut = mutate(scode, 4, 1, "0123")
    recov = "".join(map(str, hamming_decode([int(c) for c in mut], 4)))
    print((" & ".join([r"\texttt{{{}}}"] * 5) + r" \\").format(ind, scode, mut, recov, to_dna(scode)))
print(r"\ldots \\")
print(r"\bottomrule")
print(r"\end{tabular}")
\end{minted}
\caption{Formatting table of data \ref{tabhamqdata}}\label{lsthamqdatatab}
\end{longlisting}

\begin{longlisting}
\begin{minted}{python}
from hadamard_matrix import get_matrix
from hadamard_decode import find_best
from to_quat import to_quat
from as_dna import to_dna
from mutate import mutate
print(r"\begin{tabular}{ccrc} \toprule")
print(r"Code & Mutation & ID & DNA \\ \midrule")
mat = get_matrix(5)
for ind, code in takewhile(lambda ic: ic[0] < 40, enumerate(mat)):
    code_txt = "".join(map(str, map(int, code)))
    mut = [int(c) for c in mutate(code_txt, 2, 7, "01")]
    recov = find_best(mut, mat)
    print((" & ".join([r"\texttt{{{}}}"] * 4) + r" \\").format(code_txt, "".join(map(str, map(int, mut))), recov, to_dna(to_quat(code_txt))))
print(r"\ldots \\")
print(r"\bottomrule")
print(r"\end{tabular}")
\end{minted}
\caption{Formatting table of data \ref{tabhaddata}}\label{lsthaddatatab}
\end{longlisting}

\begin{longlisting}
\inputminted{postscript}{../psfiles/hamming_visualisation.ps}
\caption{Hamming index coverage}\label{lsthamps}
\end{longlisting}

\begin{longlisting}
\inputminted{python}{../src/generate_ham_vis.py}
\caption{Hadamard visualisation (uses code in \ref{lsthadps})}\label{lsthadpy}
\end{longlisting}

\begin{longlisting}
\inputminted{postscript}{../src/hadamard_template.ps}
\caption{Template for Hadamard graphic}\label{lsthadps}
\end{longlisting}

    \section{Other limitations}

    In reality, not all strings of nucleotides are well-suited to synthesis. For
    example, an overly symmetrically structured oligonucleotide may be more
    susceptable to melting at lower temperatures
    \cite{MeltingCurve1979Azbel,MeltingPoint1980Pitkin} or suffer other effects
    such as denaturation \cite{Denaturation2010Reisner}. Tools such as oligotm
    \cite{oligotm} may be used to calculate this melting temperature, and that
    would probably be a valuable addition to the code I've produced.

    \section{Source}

    This document consists of about
    \input{|"texcount dissertation.tex | awk '/^Words in text/{print $NF-1}'"}
    words, in addition to \input{|"cat ../src/*{.py,ps} | wc -w"} words of source
    code.

    All code and source \TeX/\LaTeX{} files can be found at
    \url{https://github.com/elterminad0r/EPQ}.

    Unless stated otherwise, all work has been produced by me, including
    graphics, and source code.

%TODO classifications of codes by number of correctable errors

\nocite{*}

\bibliographystyle{agsm}
\bibliography{sources}
\end{document}
